{
  "Logistic Regression": {
    "metrics": {
      "accuracy": 0.8260869565217391,
      "auc": 0.8939502630320421,
      "precision": 0.8431372549019608,
      "recall": 0.8431372549019608,
      "f1": 0.8431372549019608,
      "mcc": 0.6480153036824486
    },
    "confusion_matrix": [
      [
        66,
        16
      ],
      [
        16,
        86
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80        82\n           1       0.84      0.84      0.84       102\n\n    accuracy                           0.83       184\n   macro avg       0.82      0.82      0.82       184\nweighted avg       0.83      0.83      0.83       184\n"
  },
  "Decision Tree": {
    "metrics": {
      "accuracy": 0.7771739130434783,
      "auc": 0.8360832137733141,
      "precision": 0.801980198019802,
      "recall": 0.7941176470588235,
      "f1": 0.7980295566502463,
      "mcc": 0.5495913252238955
    },
    "confusion_matrix": [
      [
        62,
        20
      ],
      [
        21,
        81
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.75      0.76      0.75        82\n           1       0.80      0.79      0.80       102\n\n    accuracy                           0.78       184\n   macro avg       0.77      0.78      0.77       184\nweighted avg       0.78      0.78      0.78       184\n"
  },
  "kNN": {
    "metrics": {
      "accuracy": 0.842391304347826,
      "auc": 0.8677068388330942,
      "precision": 0.8411214953271028,
      "recall": 0.8823529411764706,
      "f1": 0.861244019138756,
      "mcc": 0.6801373270763298
    },
    "confusion_matrix": [
      [
        65,
        17
      ],
      [
        12,
        90
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.84      0.79      0.82        82\n           1       0.84      0.88      0.86       102\n\n    accuracy                           0.84       184\n   macro avg       0.84      0.84      0.84       184\nweighted avg       0.84      0.84      0.84       184\n"
  },
  "Naive Bayes": {
    "metrics": {
      "accuracy": 0.8260869565217391,
      "auc": 0.8874940219990435,
      "precision": 0.8365384615384616,
      "recall": 0.8529411764705882,
      "f1": 0.8446601941747572,
      "mcc": 0.6473290312799881
    },
    "confusion_matrix": [
      [
        65,
        17
      ],
      [
        15,
        87
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.81      0.79      0.80        82\n           1       0.84      0.85      0.84       102\n\n    accuracy                           0.83       184\n   macro avg       0.82      0.82      0.82       184\nweighted avg       0.83      0.83      0.83       184\n"
  },
  "Random Forest": {
    "metrics": {
      "accuracy": 0.8315217391304348,
      "auc": 0.9206121472979435,
      "precision": 0.8380952380952381,
      "recall": 0.8627450980392157,
      "f1": 0.8502415458937198,
      "mcc": 0.658148391079866
    },
    "confusion_matrix": [
      [
        65,
        17
      ],
      [
        14,
        88
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.82      0.79      0.81        82\n           1       0.84      0.86      0.85       102\n\n    accuracy                           0.83       184\n   macro avg       0.83      0.83      0.83       184\nweighted avg       0.83      0.83      0.83       184\n"
  },
  "XGBoost": {
    "metrics": {
      "accuracy": 0.8043478260869565,
      "auc": 0.8786465805834528,
      "precision": 0.8,
      "recall": 0.8627450980392157,
      "f1": 0.8301886792452831,
      "mcc": 0.6025761044575543
    },
    "confusion_matrix": [
      [
        60,
        22
      ],
      [
        14,
        88
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.81      0.73      0.77        82\n           1       0.80      0.86      0.83       102\n\n    accuracy                           0.80       184\n   macro avg       0.81      0.80      0.80       184\nweighted avg       0.80      0.80      0.80       184\n"
  }
}